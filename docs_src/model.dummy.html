---

title: Dummy Model

keywords: fastai
sidebar: home_sidebar

summary: "A small dummy model to test something quickly"
description: "A small dummy model to test something quickly"
nb_path: "nbs/01_model.dummy.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_model.dummy.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DummyModel" class="doc_header"><code>class</code> <code>DummyModel</code><a href="https://github.com/fastai/nbs_template/tree/master/nbs_template/model/dummy.py#L20" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DummyModel</code>(<strong><code>channels</code></strong>, <strong><code>width</code></strong>, <strong><code>height</code></strong>, <strong><code>num_classes</code></strong>, <strong><code>hidden_size</code></strong>=<em><code>64</code></em>, <strong><code>learning_rate</code></strong>=<em><code>0.0002</code></em>) :: <code>LightningModule</code></p>
</blockquote>
<p>DummyModel to test out something quickly</p>
<p>Args:
    channels (<code>int</code>): the channels in the input image
    width (<code>int</code>): width of the image
    height (<code>int</code>): height of the image
    hidden_size (<code>int</code>): number of channels in the hidden layers
    learning_rate (<code>float</code>): the learning rate for the optimizer</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Instantiating-Normally">Instantiating Normally<a class="anchor-link" href="#Instantiating-Normally"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">A</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
        <span class="n">A</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">CIFAR10</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">CIFAR10</span><span class="o">.</span><span class="n">std</span><span class="p">),</span>
        <span class="n">AT</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">dm</span> <span class="o">=</span> <span class="n">CIFAR10DataModule</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DummyModel</span><span class="p">(</span><span class="o">*</span><span class="n">dm</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">dm</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">progress_bar_refresh_rate</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>GPU available: False, used: False
INFO:lightning:GPU available: False, used: False
TPU available: None, using: 0 TPU cores
INFO:lightning:TPU available: None, using: 0 TPU cores
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
  | Name  | Type       | Params
-------------------------------------
0 | model | Sequential | 99.7 K
-------------------------------------
99.7 K    Trainable params
0         Non-trainable params
99.7 K    Total params
INFO:lightning:
  | Name  | Type       | Params
-------------------------------------
0 | model | Sequential | 99.7 K
-------------------------------------
99.7 K    Trainable params
0         Non-trainable params
99.7 K    Total params
/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 13:18:35.626 | INFO     | __main__:validation_epoch_end:72 - val_loss: 2.3227691650390625, val_acc: 0.09375
/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 13:18:46.124 | INFO     | __main__:validation_epoch_end:72 - val_loss: 1.6776868104934692, val_acc: 0.4112261235713959
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 13:18:48.150 | INFO     | __main__:test_epoch_end:87 - test_acc: 0.4146365821361542
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{&#39;test_acc&#39;: tensor(0.4146),
 &#39;val_acc&#39;: tensor(0.4112),
 &#39;val_loss&#39;: tensor(1.6777)}
--------------------------------------------------------------------------------
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;val_loss&#39;: 1.6776868104934692,
  &#39;val_acc&#39;: 0.4112261235713959,
  &#39;test_acc&#39;: 0.4146365821361542}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Instantiating-using-Hydra-dataclass">Instantiating using Hydra dataclass<a class="anchor-link" href="#Instantiating-using-Hydra-dataclass"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">hydra</span>
<span class="kn">from</span> <span class="nn">omegaconf</span> <span class="kn">import</span> <span class="n">OmegaConf</span>

<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span> <span class="nn">hydra.core.config_store</span> <span class="kn">import</span> <span class="n">ConfigStore</span>
<span class="kn">from</span> <span class="nn">hydra.utils</span> <span class="kn">import</span> <span class="n">instantiate</span>
<span class="kn">from</span> <span class="nn">hydra.experimental</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">initialize</span><span class="p">,</span>
    <span class="n">initialize_config_module</span><span class="p">,</span>
    <span class="n">initialize_config_dir</span><span class="p">,</span>
    <span class="n">compose</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">importlib</span> <span class="kn">import</span> <span class="n">import_module</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">:</span>
    <span class="n">_target_</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;nbs_template.model.dummy.DummyModel&quot;</span>
    <span class="n">channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">height</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2e-4</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DataModuleConfig</span><span class="p">:</span>
    <span class="nb">type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;nbs_template.data.cifar.CIFAR10DataModule&quot;</span>
    <span class="n">transform</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;A.Resize(32, 32)&quot;</span><span class="p">,</span>
            <span class="s2">&quot;A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)&quot;</span><span class="p">,</span>
            <span class="s2">&quot;AT.ToTensor()&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TrainingConfig</span><span class="p">:</span>
    <span class="n">_target_</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;pytorch_lightning.Trainer&quot;</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">progress_bar_refresh_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DummyTrainingConfig</span><span class="p">:</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">ModelConfig</span> <span class="o">=</span> <span class="n">ModelConfig</span>
    <span class="n">dm_config</span><span class="p">:</span> <span class="n">DataModuleConfig</span> <span class="o">=</span> <span class="n">DataModuleConfig</span>
    <span class="n">trainer_config</span><span class="p">:</span> <span class="n">TrainingConfig</span> <span class="o">=</span> <span class="n">TrainingConfig</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cs</span><span class="p">:</span> <span class="n">ConfigStore</span> <span class="o">=</span> <span class="n">ConfigStore</span><span class="o">.</span><span class="n">instance</span><span class="p">()</span>
<span class="n">cs</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;dummy_config&quot;</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="n">DummyTrainingConfig</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">initialize</span><span class="p">(</span><span class="n">config_path</span><span class="o">=</span><span class="s2">&quot;configs&quot;</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s2">&quot;app&quot;</span><span class="p">):</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">compose</span><span class="p">(</span><span class="n">config_name</span><span class="o">=</span><span class="s2">&quot;dummy_config&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;model_config&#39;: {&#39;_target_&#39;: &#39;nbs_template.model.dummy.DummyModel&#39;, &#39;channels&#39;: 3, &#39;width&#39;: 32, &#39;height&#39;: 32, &#39;num_classes&#39;: 10, &#39;hidden_size&#39;: 32, &#39;learning_rate&#39;: 0.0002}, &#39;dm_config&#39;: {&#39;type&#39;: &#39;nbs_template.data.cifar.CIFAR10DataModule&#39;, &#39;transform&#39;: [&#39;A.Resize(32, 32)&#39;, &#39;A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)&#39;, &#39;AT.ToTensor()&#39;]}, &#39;trainer_config&#39;: {&#39;_target_&#39;: &#39;pytorch_lightning.Trainer&#39;, &#39;max_epochs&#39;: 1, &#39;progress_bar_refresh_rate&#39;: 20}}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_yaml</span><span class="p">(</span><span class="n">cfg</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>model_config:
  _target_: nbs_template.model.dummy.DummyModel
  channels: 3
  width: 32
  height: 32
  num_classes: 10
  hidden_size: 32
  learning_rate: 0.0002
dm_config:
  type: nbs_template.data.cifar.CIFAR10DataModule
  transform:
  - A.Resize(32, 32)
  - A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)
  - AT.ToTensor()
trainer_config:
  _target_: pytorch_lightning.Trainer
  max_epochs: 1
  progress_bar_refresh_rate: 20

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="nb">eval</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dm_config</span><span class="o">.</span><span class="n">transform</span><span class="p">])</span>
<span class="n">dm_module_path</span><span class="p">,</span> <span class="n">dm_class</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dm_config</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">dm_module</span> <span class="o">=</span> <span class="n">import_module</span><span class="p">(</span><span class="n">dm_module_path</span><span class="p">)</span>
<span class="n">dm</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dm_module</span><span class="p">,</span> <span class="n">dm_class</span><span class="p">)(</span><span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">trainer_config</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>GPU available: False, used: False
TPU available: None, using: 0 TPU cores
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
  | Name  | Type       | Params
-------------------------------------
0 | model | Sequential | 99.7 K
-------------------------------------
99.7 K    Trainable params
0         Non-trainable params
99.7 K    Total params
/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 14:16:30.295 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 2.3173904418945312, val_acc: 0.125
/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 14:16:40.879 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 1.6747769117355347, val_acc: 0.41401273012161255
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 14:17:22.673 | INFO     | nbs_template.model.dummy:test_epoch_end:105 - test_acc: 0.41383785009384155
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{&#39;test_acc&#39;: tensor(0.4138),
 &#39;val_acc&#39;: tensor(0.4140),
 &#39;val_loss&#39;: tensor(1.6748)}
--------------------------------------------------------------------------------
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;val_loss&#39;: 1.6747769117355347,
  &#39;val_acc&#39;: 0.41401273012161255,
  &#39;test_acc&#39;: 0.41383785009384155}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Instantiating-using-Hydra-config-files">Instantiating using Hydra config files<a class="anchor-link" href="#Instantiating-using-Hydra-config-files"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%file</span> configs/dummy.yaml
<span class="n">model_config</span><span class="p">:</span>
  <span class="n">_target_</span><span class="p">:</span> <span class="n">nbs_template</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dummy</span><span class="o">.</span><span class="n">DummyModel</span>
  <span class="n">channels</span><span class="p">:</span> <span class="mi">3</span>
  <span class="n">width</span><span class="p">:</span> <span class="mi">32</span>
  <span class="n">height</span><span class="p">:</span> <span class="mi">32</span>
  <span class="n">num_classes</span><span class="p">:</span> <span class="mi">10</span>
  <span class="n">hidden_size</span><span class="p">:</span> <span class="mi">32</span>
  <span class="n">learning_rate</span><span class="p">:</span> <span class="mf">0.0002</span>
<span class="n">dm_config</span><span class="p">:</span>
  <span class="nb">type</span><span class="p">:</span> <span class="n">nbs_template</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cifar</span><span class="o">.</span><span class="n">CIFAR10DataModule</span>
  <span class="n">transform</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">A</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
  <span class="o">-</span> <span class="n">A</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">CIFAR10</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">CIFAR10</span><span class="o">.</span><span class="n">std</span><span class="p">)</span>
  <span class="o">-</span> <span class="n">AT</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="n">trainer_config</span><span class="p">:</span>
  <span class="n">_target_</span><span class="p">:</span> <span class="n">pytorch_lightning</span><span class="o">.</span><span class="n">Trainer</span>
  <span class="n">max_epochs</span><span class="p">:</span> <span class="mi">1</span>
  <span class="n">progress_bar_refresh_rate</span><span class="p">:</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Writing configs/dummy.yaml
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">initialize</span><span class="p">(</span><span class="n">config_path</span><span class="o">=</span><span class="s2">&quot;configs&quot;</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s2">&quot;app&quot;</span><span class="p">):</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">compose</span><span class="p">(</span><span class="n">config_name</span><span class="o">=</span><span class="s2">&quot;dummy.yaml&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cfg</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;model_config&#39;: {&#39;_target_&#39;: &#39;nbs_template.model.dummy.DummyModel&#39;, &#39;channels&#39;: 3, &#39;width&#39;: 32, &#39;height&#39;: 32, &#39;num_classes&#39;: 10, &#39;hidden_size&#39;: 32, &#39;learning_rate&#39;: 0.0002}, &#39;dm_config&#39;: {&#39;type&#39;: &#39;nbs_template.data.cifar.CIFAR10DataModule&#39;, &#39;transform&#39;: [&#39;A.Resize(32, 32)&#39;, &#39;A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)&#39;, &#39;AT.ToTensor()&#39;]}, &#39;trainer_config&#39;: {&#39;_target_&#39;: &#39;pytorch_lightning.Trainer&#39;, &#39;max_epochs&#39;: 1, &#39;progress_bar_refresh_rate&#39;: 20}}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="nb">eval</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dm_config</span><span class="o">.</span><span class="n">transform</span><span class="p">])</span>
<span class="n">dm_module_path</span><span class="p">,</span> <span class="n">dm_class</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dm_config</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">dm_module</span> <span class="o">=</span> <span class="n">import_module</span><span class="p">(</span><span class="n">dm_module_path</span><span class="p">)</span>
<span class="n">dm</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dm_module</span><span class="p">,</span> <span class="n">dm_class</span><span class="p">)(</span><span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">trainer_config</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>GPU available: False, used: False
TPU available: None, using: 0 TPU cores
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
  | Name  | Type       | Params
-------------------------------------
0 | model | Sequential | 99.7 K
-------------------------------------
99.7 K    Trainable params
0         Non-trainable params
99.7 K    Total params
/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 14:25:21.618 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 2.312533378601074, val_acc: 0.046875
/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 14:25:31.941 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 1.7183785438537598, val_acc: 0.39729300141334534
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
2020-12-15 14:25:33.916 | INFO     | nbs_template.model.dummy:test_epoch_end:105 - test_acc: 0.4044528901576996
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{&#39;test_acc&#39;: tensor(0.4045),
 &#39;val_acc&#39;: tensor(0.3973),
 &#39;val_loss&#39;: tensor(1.7184)}
--------------------------------------------------------------------------------
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;val_loss&#39;: 1.7183785438537598,
  &#39;val_acc&#39;: 0.39729300141334534,
  &#39;test_acc&#39;: 0.4044528901576996}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev.export</span> <span class="kn">import</span> <span class="n">notebook2script</span>

<span class="n">notebook2script</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted 00_data.cifar.ipynb.
Converted 01_model.dummy.ipynb.
Converted index.ipynb.
Converted template_nb.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 


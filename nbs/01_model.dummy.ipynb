{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Model\n",
    "\n",
    "> A small dummy model to test something quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import albumentations as A\n",
    "import albumentations.pytorch.transforms as AT\n",
    "\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from nbs_template.data.cifar import CIFAR10DataModule, CIFAR10\n",
    "\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DummyModel(pl.LightningModule):\n",
    "    \"\"\"DummyModel to test out something quickly\n",
    "\n",
    "    Args:\n",
    "        channels (`int`): the channels in the input image\n",
    "        width (`int`): width of the image\n",
    "        height (`int`): height of the image\n",
    "        hidden_size (`int`): number of channels in the hidden layers\n",
    "        learning_rate (`float`): the learning rate for the optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, channels, width, height, num_classes, hidden_size=64, learning_rate=2e-4\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # We take in input dimensions as parameters and use those to dynamically build model.\n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.mean(torch.tensor([x[\"loss\"] for x in outputs]))\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        avg_acc = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "\n",
    "        self.log_dict({\"val_loss\": avg_loss, \"val_acc\": avg_acc})\n",
    "\n",
    "        logger.info(f\"val_loss: {avg_loss}, val_acc: {avg_acc}\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        return {\"test_acc\": acc}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
    "\n",
    "        self.log(\"test_acc\", avg_acc)\n",
    "\n",
    "        logger.info(f\"test_acc: {avg_acc}\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating Normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "INFO:lightning:GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 99.7 K\n",
      "-------------------------------------\n",
      "99.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "99.7 K    Total params\n",
      "INFO:lightning:\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 99.7 K\n",
      "-------------------------------------\n",
      "99.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "99.7 K    Total params\n",
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9eb4c3c9cf44dab1d6fb1dd39b70a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 13:18:35.626 | INFO     | __main__:validation_epoch_end:72 - val_loss: 2.3227691650390625, val_acc: 0.09375\n",
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6091c6ead94b6e89d46a9ec9b49191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 13:18:46.124 | INFO     | __main__:validation_epoch_end:72 - val_loss: 1.6776868104934692, val_acc: 0.4112261235713959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(32, 32),\n",
    "        A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std),\n",
    "        AT.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "dm = CIFAR10DataModule(transform=transform)\n",
    "model = DummyModel(*dm.size(), dm.num_classes, hidden_size=32)\n",
    "trainer = pl.Trainer(max_epochs=1, progress_bar_refresh_rate=20)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc3a35e5df6442f9c606123e8c75462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 13:18:48.150 | INFO     | __main__:test_epoch_end:87 - test_acc: 0.4146365821361542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.4146),\n",
      " 'val_acc': tensor(0.4112),\n",
      " 'val_loss': tensor(1.6777)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.6776868104934692,\n",
       "  'val_acc': 0.4112261235713959,\n",
       "  'test_acc': 0.4146365821361542}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating using Hydra dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from hydra.core.config_store import ConfigStore\n",
    "from hydra.utils import instantiate\n",
    "from hydra.experimental import (\n",
    "    initialize,\n",
    "    initialize_config_module,\n",
    "    initialize_config_dir,\n",
    "    compose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    _target_: str = \"nbs_template.model.dummy.DummyModel\"\n",
    "    channels: int = 3\n",
    "    width: int = 32\n",
    "    height: int = 32\n",
    "    num_classes: int = 10\n",
    "    hidden_size: int = 32\n",
    "    learning_rate: float = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataModuleConfig:\n",
    "    type: str = \"nbs_template.data.cifar.CIFAR10DataModule\"\n",
    "    transform: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"A.Resize(32, 32)\",\n",
    "            \"A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)\",\n",
    "            \"AT.ToTensor()\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    _target_: str = \"pytorch_lightning.Trainer\"\n",
    "    max_epochs: int = 1\n",
    "    progress_bar_refresh_rate: int = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DummyTrainingConfig:\n",
    "    model_config: ModelConfig = ModelConfig\n",
    "    dm_config: DataModuleConfig = DataModuleConfig\n",
    "    trainer_config: TrainingConfig = TrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs: ConfigStore = ConfigStore.instance()\n",
    "cs.store(name=\"dummy_config\", node=DummyTrainingConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"configs\", job_name=\"app\"):\n",
    "    cfg = compose(config_name=\"dummy_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_config': {'_target_': 'nbs_template.model.dummy.DummyModel', 'channels': 3, 'width': 32, 'height': 32, 'num_classes': 10, 'hidden_size': 32, 'learning_rate': 0.0002}, 'dm_config': {'type': 'nbs_template.data.cifar.CIFAR10DataModule', 'transform': ['A.Resize(32, 32)', 'A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)', 'AT.ToTensor()']}, 'trainer_config': {'_target_': 'pytorch_lightning.Trainer', 'max_epochs': 1, 'progress_bar_refresh_rate': 20}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config:\n",
      "  _target_: nbs_template.model.dummy.DummyModel\n",
      "  channels: 3\n",
      "  width: 32\n",
      "  height: 32\n",
      "  num_classes: 10\n",
      "  hidden_size: 32\n",
      "  learning_rate: 0.0002\n",
      "dm_config:\n",
      "  type: nbs_template.data.cifar.CIFAR10DataModule\n",
      "  transform:\n",
      "  - A.Resize(32, 32)\n",
      "  - A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)\n",
      "  - AT.ToTensor()\n",
      "trainer_config:\n",
      "  _target_: pytorch_lightning.Trainer\n",
      "  max_epochs: 1\n",
      "  progress_bar_refresh_rate: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model_config)\n",
    "transforms = A.Compose([eval(x) for x in cfg.dm_config.transform])\n",
    "dm_module_path, dm_class = cfg.dm_config.type.rsplit(\".\", 1)\n",
    "dm_module = import_module(dm_module_path)\n",
    "dm = getattr(dm_module, dm_class)(transform=transforms)\n",
    "trainer = instantiate(cfg.trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 99.7 K\n",
      "-------------------------------------\n",
      "99.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "99.7 K    Total params\n",
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3f3a5d38994c64bf3f826a4e301eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 14:16:30.295 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 2.3173904418945312, val_acc: 0.125\n",
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2805cb0b3b44fdb81a70227bb73c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 14:16:40.879 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 1.6747769117355347, val_acc: 0.41401273012161255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2de46ba173c4616adbb1ad77f6fcf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 14:17:22.673 | INFO     | nbs_template.model.dummy:test_epoch_end:105 - test_acc: 0.41383785009384155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.4138),\n",
      " 'val_acc': tensor(0.4140),\n",
      " 'val_loss': tensor(1.6748)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.6747769117355347,\n",
       "  'val_acc': 0.41401273012161255,\n",
       "  'test_acc': 0.41383785009384155}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating using Hydra config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing configs/dummy.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file configs/dummy.yaml\n",
    "model_config:\n",
    "  _target_: nbs_template.model.dummy.DummyModel\n",
    "  channels: 3\n",
    "  width: 32\n",
    "  height: 32\n",
    "  num_classes: 10\n",
    "  hidden_size: 32\n",
    "  learning_rate: 0.0002\n",
    "dm_config:\n",
    "  type: nbs_template.data.cifar.CIFAR10DataModule\n",
    "  transform:\n",
    "  - A.Resize(32, 32)\n",
    "  - A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)\n",
    "  - AT.ToTensor()\n",
    "trainer_config:\n",
    "  _target_: pytorch_lightning.Trainer\n",
    "  max_epochs: 1\n",
    "  progress_bar_refresh_rate: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"configs\", job_name=\"app\"):\n",
    "    cfg = compose(config_name=\"dummy.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_config': {'_target_': 'nbs_template.model.dummy.DummyModel', 'channels': 3, 'width': 32, 'height': 32, 'num_classes': 10, 'hidden_size': 32, 'learning_rate': 0.0002}, 'dm_config': {'type': 'nbs_template.data.cifar.CIFAR10DataModule', 'transform': ['A.Resize(32, 32)', 'A.Normalize(mean=CIFAR10.mean, std=CIFAR10.std)', 'AT.ToTensor()']}, 'trainer_config': {'_target_': 'pytorch_lightning.Trainer', 'max_epochs': 1, 'progress_bar_refresh_rate': 20}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model_config)\n",
    "transforms = A.Compose([eval(x) for x in cfg.dm_config.transform])\n",
    "dm_module_path, dm_class = cfg.dm_config.type.rsplit(\".\", 1)\n",
    "dm_module = import_module(dm_module_path)\n",
    "dm = getattr(dm_module, dm_class)(transform=transforms)\n",
    "trainer = instantiate(cfg.trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 99.7 K\n",
      "-------------------------------------\n",
      "99.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "99.7 K    Total params\n",
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ab4dd7ac134002b2be077df576ddaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 14:25:21.618 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 2.312533378601074, val_acc: 0.046875\n",
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e984c725c7423896f48005d66ea63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 14:25:31.941 | INFO     | nbs_template.model.dummy:validation_epoch_end:90 - val_loss: 1.7183785438537598, val_acc: 0.39729300141334534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shadowleaf/anaconda3/envs/dev-ink/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6edcca45924eab8c7413a7427daaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-15 14:25:33.916 | INFO     | nbs_template.model.dummy:test_epoch_end:105 - test_acc: 0.4044528901576996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.4045),\n",
      " 'val_acc': tensor(0.3973),\n",
      " 'val_loss': tensor(1.7184)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.7183785438537598,\n",
       "  'val_acc': 0.39729300141334534,\n",
       "  'test_acc': 0.4044528901576996}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.cifar.ipynb.\n",
      "Converted 01_model.dummy.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted template_nb.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
